% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/score_model_out.R
\name{score_model_out}
\alias{score_model_out}
\title{Score model output predictions}
\usage{
score_model_out(
  model_out_tbl,
  oracle_output,
  metrics = NULL,
  summarize = TRUE,
  by = "model_id",
  output_type_id_order = NULL
)
}
\arguments{
\item{model_out_tbl}{Model output tibble with predictions}

\item{oracle_output}{Predictions that would have been generated by an oracle
model that knew the observed target data values in advance}

\item{metrics}{Character vector of scoring metrics to compute. If \code{NULL}
(the default), appropriate metrics are chosen automatically. See details
for more.}

\item{summarize}{Boolean indicator of whether summaries of forecast scores
should be computed. Defaults to \code{TRUE}.}

\item{by}{Character vector naming columns to summarize by. For example,
specifying \code{by = "model_id"} (the default) will compute average scores for
each model.}

\item{output_type_id_order}{For ordinal variables in pmf format, this is a
vector of levels for pmf forecasts, in increasing order of the levels. For
all other output types, this is ignored.}
}
\value{
A data.table with scores
}
\description{
Scores model outputs with a single \code{output_type} against observed data.
}
\details{
See the hubverse documentation for the expected format of the
\href{https://hubverse.io/en/latest/user-guide/target-data.html#oracle-output}{oracle output data}.

Default metrics are provided by the \code{scoringutils} package. You can select
metrics by passing in a character vector of metric names to the \code{metrics}
argument.

The following metrics can be selected (all are used by default) for the
different \code{output_type}s:

\strong{Quantile forecasts:} (\code{output_type == "quantile"})
\itemize{
\item wis
\item overprediction
\item underprediction
\item dispersion
\item bias
\item ae_median
\item "interval_coverage_XX": interval coverage at the "XX" level. For example,
"interval_coverage_95" is the 95\% interval coverage rate, which would be calculated
based on quantiles at the probability levels 0.025 and 0.975.
}

See \link[scoringutils:get_metrics.forecast_quantile]{scoringutils::get_metrics.forecast_quantile} for details.

\strong{Nominal forecasts:} (\code{output_type == "pmf"} and \code{output_type_id_order} is \code{NULL})
\itemize{
\item log_score
}

See \link[scoringutils:get_metrics.forecast_nominal]{scoringutils::get_metrics.forecast_nominal} for details.

\strong{Ordinal forecasts:} (\code{output_type == "pmf"} and \code{output_type_id_order} is a vector)
\itemize{
\item log_score
\item rps
}

See \link[scoringutils:get_metrics.forecast_ordinal]{scoringutils::get_metrics.forecast_ordinal} for details.

\strong{Median forecasts:} (\code{output_type == "median"})
\itemize{
\item ae_point: absolute error of the point forecast (recommended for the median, see Gneiting (2011))
}

See \link[scoringutils:get_metrics.forecast_point]{scoringutils::get_metrics.forecast_point} for details.

\strong{Mean forecasts:} (\code{output_type == "mean"})
\itemize{
\item \code{se_point}: squared error of the point forecast (recommended for the mean, see Gneiting (2011))
}
}
\examples{
\dontshow{if (requireNamespace("hubExamples", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# compute WIS and interval coverage rates at 80\% and 90\% levels based on
# quantile forecasts, summarized by the mean score for each model
quantile_scores <- score_model_out(
  model_out_tbl = hubExamples::forecast_outputs |>
    dplyr::filter(.data[["output_type"]] == "quantile"),
  oracle_output = hubExamples::forecast_oracle_output,
  metrics = c("wis", "interval_coverage_80", "interval_coverage_90"),
  by = "model_id"
)
quantile_scores

# compute log scores based on pmf predictions for categorical targets,
# summarized by the mean score for each combination of model and location.
# Note: if the model_out_tbl had forecasts for multiple targets using a
# pmf output_type with different bins, it would be necessary to score the
# predictions for those targets separately.
pmf_scores <- score_model_out(
  model_out_tbl = hubExamples::forecast_outputs |>
    dplyr::filter(.data[["output_type"]] == "pmf"),
  oracle_output = hubExamples::forecast_oracle_output,
  metrics = c("log_score", "rps"),
  by = c("model_id", "location", "horizon"),
  output_type_id_order = c("low", "moderate", "high", "very high")
)
head(pmf_scores)
\dontshow{\}) # examplesIf}
}
\references{
Gneiting, Tilmann. 2011. "Making and Evaluating Point Forecasts." Journal of the
American Statistical Association 106 (494): 746â€“62. <doi: 10.1198/jasa.2011.r10138>.
}
