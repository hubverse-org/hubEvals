[{"path":[]},{"path":"https://hubverse-org.github.io/hubEvals/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying standards acceptable behavior. Enforcement responsibility Code Conduct Committee, take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Instances abusive, harassing, otherwise unacceptable behavior may reported member Code Conduct Committee. complaints reviewed investigated promptly fairly. Code Conduct Committee use Enforcement Manual determining consequences action deem violation Code Conduct. community leaders Code Conduct Committee members obligated respect privacy security reporter incident.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to hubEvals","title":"Contributing to hubEvals","text":"outlines propose change hubEvals. general info contributing , hubverse packages, please see hubverse community page. can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to hubEvals","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). procedures contributing bigger changes, code particular, generally follow advised tidyverse dev team, including following tidyverse style guide code recording user facing changes NEWS.md.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to hubEvals","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"hubverse-org/hubEvals\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Follow pull request checklist create Git branch pull request (PR). recommend using usethis::pr_init(\"name/brief-description/issue\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first heading—usually labelled “development version”). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to hubEvals","text":"New code follow tidyverse style guide. use Air code formatting. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CONTRIBUTING.html","id":"setting-up-air","dir":"","previous_headings":"Bigger changes > Code style","what":"Setting up Air","title":"Contributing to hubEvals","text":"project contains configuration files (air.toml, .vscode/) ensure formatting scoped repository —personal projects remain unaffected. Positron Air ships built-Positron. project settings already configured, format--save enabled automatically working repo. VS Code Install Air extension project settings already configured, format--save enabled automatically working repo RStudio (2024.12.0+) RStudio requires manual setup. Note RStudio support per-project settings, global options. macOS/Linux: curl -LsSf https://github.com/posit-dev/air/releases/latest/download/air-installer.sh | sh macOS (Homebrew): brew install air Windows: powershell -ExecutionPolicy Bypass -c \"irm https://github.com/posit-dev/air/releases/latest/download/air-installer.ps1 | iex\" Check “Use external formatter” Set “Reformat command:” {path//air} format (find path air macOS/Linux) See RStudio setup guide details settings pane, check “Format code save” Note: applies projects, just hubverse repos Use Code > Reformat Code (Cmd/Ctrl+Shift+) right-click select “Reformat Code” CI check formatting PRs fail code formatted Command Line Works terminal: - Format entire project: air format . - Check without modifying: air format . --check","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to hubEvals","text":"Please note hubEvals project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 hubEvals authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nicholas Reich. Author, maintainer. Evan Ray. Author. Nikos Bosse. Author. Matthew Cornell. Author. Zhian Kamvar. Contributor. Li Shandross. Contributor. Becky Sweger. Author. Kimberlyn Roosa. Author.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reich N, Ray E, Bosse N, Cornell M, Sweger B, Roosa K (2026). hubEvals: Basic tools scoring hubverse forecasts. R package version 0.1.0.9000, https://hubverse-org.github.io/hubEvals/.","code":"@Manual{,   title = {hubEvals: Basic tools for scoring hubverse forecasts},   author = {Nicholas Reich and Evan Ray and Nikos Bosse and Matthew Cornell and Becky Sweger and Kimberlyn Roosa},   year = {2026},   note = {R package version 0.1.0.9000},   url = {https://hubverse-org.github.io/hubEvals/}, }"},{"path":"https://hubverse-org.github.io/hubEvals/dev/index.html","id":"hubevals-","dir":"","previous_headings":"","what":"Basic tools for scoring hubverse forecasts","title":"Basic tools for scoring hubverse forecasts","text":"goal hubEvals provide tools evaluating infectious disease model outputs. package part Hubverse project, aims provide suite tools infectious disease modeling hubs.","code":""},{"path":[]},{"path":"https://hubverse-org.github.io/hubEvals/dev/index.html","id":"latest","dir":"","previous_headings":"Installation","what":"Latest","title":"Basic tools for scoring hubverse forecasts","text":"can install latest version hubEvals R-universe:","code":"install.packages(\"hubEvals\", repos = c(\"https://hubverse-org.r-universe.dev\", \"https://cloud.r-project.org\"))"},{"path":"https://hubverse-org.github.io/hubEvals/dev/index.html","id":"development","dir":"","previous_headings":"Installation","what":"Development","title":"Basic tools for scoring hubverse forecasts","text":"want test new features yet released, can install development version hubEvals GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"hubverse-org/hubEvals\")"},{"path":"https://hubverse-org.github.io/hubEvals/dev/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Basic tools for scoring hubverse forecasts","text":"Predictions can evaluated directly using scoring function hubEvals, assumes hubverse format model outputs target data: , users may transform predictions forecast object can used input scoringutils functions use tooling directly.","code":"library(hubEvals)  # compute default metrics (in this case, absolute error) for # median forecasts, summarized by the mean score for each model median_scores <- score_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(output_type == \"median\"), # only one output type allowed   oracle_output = hubExamples::forecast_oracle_output,   by = \"model_id\" ) median_scores #>             model_id ae_point #>               <char>    <num> #> 1: Flusight-baseline  401.875 #> 2:   MOBS-GLEAM_FLUH  416.375 #> 3:          PSI-DICE  277.000 # compute WIS and interval coverage rates at 80% and 90% levels based on # quantile forecasts, summarized by the mean score for each model quantile_scores <- score_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(output_type == \"quantile\"), # only one output type allowed   oracle_output = hubExamples::forecast_oracle_output,   metrics = c(\"wis\", \"interval_coverage_80\", \"interval_coverage_90\"),   relative_metrics = \"wis\",   by = \"model_id\" ) quantile_scores #> Key: <model_id> #>             model_id      wis interval_coverage_80 interval_coverage_90 wis_relative_skill #>               <char>    <num>                <num>                <num>              <num> #> 1: Flusight-baseline 329.4545                  0.0               0.1250          1.1473659 #> 2:   MOBS-GLEAM_FLUH 315.2393                  0.5               0.5625          1.0978597 #> 3:          PSI-DICE 227.9527                  0.5               0.5000          0.7938733 # compute log scores based on pmf predictions for categorical targets, # summarized by the mean score for each combination of model and location. # Note: if the model_out_tbl had forecasts for multiple targets using a # pmf output_type with different bins, it would be necessary to score the # predictions for those targets separately. pmf_scores <- score_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(output_type == \"pmf\"), # only one output type allowed   oracle_output = hubExamples::forecast_oracle_output,   metrics = c(\"log_score\", \"rps\"),   by = c(\"model_id\", \"location\", \"horizon\"),   output_type_id_order = c(\"low\", \"moderate\", \"high\", \"very high\") ) head(pmf_scores) #>             model_id location horizon   log_score          rps #>               <char>   <char>   <int>       <num>        <num> #> 1: Flusight-baseline       25       0  0.02107606 0.0008531043 #> 2: Flusight-baseline       25       1  6.69652380 0.5029240066 #> 3: Flusight-baseline       25       2 17.73313203 1.0057355863 #> 4: Flusight-baseline       25       3         Inf 1.8665126816 #> 5: Flusight-baseline       48       0  2.18418007 0.4873966597 #> 6: Flusight-baseline       48       1  7.49960792 0.9659026096 median_forecast <- transform_point_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(output_type == \"median\"),   oracle_output = hubExamples::forecast_oracle_output,   output_type = \"median\" ) median_forecast  quantile_forecast <- transform_quantile_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(output_type == \"quantile\"),   oracle_output = hubExamples::forecast_oracle_output ) quantile_forecast  pmf_forecasts <- transform_pmf_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(output_type == \"pmf\"),   oracle_output = hubExamples::forecast_oracle_output,   output_type_id_order = c(\"low\", \"moderate\", \"high\", \"very high\") ) pmf_forecasts"},{"path":"https://hubverse-org.github.io/hubEvals/dev/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Basic tools for scoring hubverse forecasts","text":"Please note hubEvals package released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Basic tools for scoring hubverse forecasts","text":"Interested contributing back open-source Hubverse project? Learn get involved Hubverse Community contribute hubEvals package.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/score_model_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Score model output predictions — score_model_out","title":"Score model output predictions — score_model_out","text":"Scores model outputs single output_type observed data.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/score_model_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score model output predictions — score_model_out","text":"","code":"score_model_out(   model_out_tbl,   oracle_output,   metrics = NULL,   relative_metrics = NULL,   baseline = NULL,   summarize = TRUE,   by = \"model_id\",   output_type_id_order = NULL,   transform = NULL,   transform_append = FALSE,   transform_label = NULL,   ... )"},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/score_model_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score model output predictions — score_model_out","text":"model_out_tbl Model output tibble predictions oracle_output Predictions generated oracle model knew observed target data values advance metrics Character vector scoring metrics compute. NULL (default), appropriate metrics chosen automatically. See details . relative_metrics Character vector scoring metrics compute relative skill scores. relative_metrics subset metrics include proper scores (e.g., contain interval coverage metrics).  NULL (default), relative metrics computed.  Relative metrics computed summarize = TRUE, require \"model_id\" included . baseline String name model use baseline relative skill scores. baseline given, scaled relative skill respect baseline returned. default (NULL), relative skill scaled respect baseline model. summarize Boolean indicator whether summaries forecast scores computed. Defaults TRUE. Character vector naming columns summarize . example, specifying = \"model_id\" (default) compute average scores model. output_type_id_order ordinal variables pmf format, vector levels pmf forecasts, increasing order levels. order values output_type_id can found referencing hub's tasks.json configuration file. output types pmf, ignored. transform function apply scale transformation predictions observations scoring. Common choices include log_shift (recommended log transformation handles zeros via offset parameter), sqrt, log1p. Avoid using log directly data may contain zeros. NULL (default), transformation applied. supported quantile, mean, median output types. transform_append Logical. FALSE (default), scores computed transformed scale. TRUE, scores computed original transformed scales, scale column distinguishing . Ignored transform = NULL. transform_label character string label transformation (e.g., \"log\"). NULL (default), label auto-generated function name (e.g., \"log_shift\" scoringutils::log_shift). Required using anonymous transform function. Ignored transform = NULL. Note: label appears output transform_append = TRUE, distinguishes transformed rows (labeled value) original rows (labeled \"natural\") scale column. ... Additional arguments passed transform function. example, allows use offset base arguments scoringutils::log_shift(). Ignored transform = NULL.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/score_model_out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score model output predictions — score_model_out","text":"data.table scores","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/score_model_out.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Score model output predictions — score_model_out","text":"See hubverse documentation expected format oracle output data. Default metrics provided scoringutils package. can select metrics passing character vector metric names metrics argument. following metrics can selected (used default) different output_types: Quantile forecasts: (output_type == \"quantile\") wis overprediction underprediction dispersion bias ae_median \"interval_coverage_XX\": interval coverage \"XX\" level. example, \"interval_coverage_95\" 95% interval coverage rate, calculated based quantiles probability levels 0.025 0.975. See scoringutils::get_metrics.forecast_quantile details. Nominal forecasts: (output_type == \"pmf\" output_type_id_order NULL) log_score See scoringutils::get_metrics.forecast_nominal details. Ordinal forecasts: (output_type == \"pmf\" output_type_id_order vector) log_score rps See scoringutils::get_metrics.forecast_ordinal details. Median forecasts: (output_type == \"median\") ae_point: absolute error point forecast (recommended median, see Gneiting (2011)) See scoringutils::get_metrics.forecast_point details. Mean forecasts: (output_type == \"mean\") se_point: squared error point forecast (recommended mean, see Gneiting (2011)) See scoringutils::add_relative_skill details relative skill scores.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/score_model_out.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Score model output predictions — score_model_out","text":"Gneiting, Tilmann. 2011. \"Making Evaluating Point Forecasts.\" Journal American Statistical Association 106 (494): 746–62. <doi: 10.1198/jasa.2011.r10138>.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/score_model_out.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Score model output predictions — score_model_out","text":"","code":"# compute WIS and interval coverage rates at 80% and 90% levels based on # quantile forecasts, summarized by the mean score for each model quantile_scores <- score_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(.data[[\"output_type\"]] == \"quantile\"),   oracle_output = hubExamples::forecast_oracle_output,   metrics = c(\"wis\", \"interval_coverage_80\", \"interval_coverage_90\"),   relative_metrics = \"wis\",   by = \"model_id\" ) quantile_scores #> Key: <model_id> #>             model_id      wis interval_coverage_80 interval_coverage_90 #>               <char>    <num>                <num>                <num> #> 1: Flusight-baseline 329.4545                  0.0               0.1250 #> 2:   MOBS-GLEAM_FLUH 315.2393                  0.5               0.5625 #> 3:          PSI-DICE 227.9527                  0.5               0.5000 #>    wis_relative_skill #>                 <num> #> 1:          1.1473659 #> 2:          1.0978597 #> 3:          0.7938733  # compute log scores based on pmf predictions for categorical targets, # summarized by the mean score for each combination of model and location. # Note: if the model_out_tbl had forecasts for multiple targets using a # pmf output_type with different bins, it would be necessary to score the # predictions for those targets separately. pmf_scores <- score_model_out(   model_out_tbl = hubExamples::forecast_outputs |>     dplyr::filter(.data[[\"output_type\"]] == \"pmf\"),   oracle_output = hubExamples::forecast_oracle_output,   metrics = c(\"log_score\", \"rps\"),   by = c(\"model_id\", \"location\", \"horizon\"),   output_type_id_order = c(\"low\", \"moderate\", \"high\", \"very high\") ) head(pmf_scores) #>             model_id location horizon   log_score          rps #>               <char>   <char>   <int>       <num>        <num> #> 1: Flusight-baseline       25       0  0.02107606 0.0008531043 #> 2: Flusight-baseline       25       1  6.69652380 0.5029240066 #> 3: Flusight-baseline       25       2 17.73313203 1.0057355863 #> 4: Flusight-baseline       25       3         Inf 1.8665126816 #> 5: Flusight-baseline       48       0  2.18418007 0.4873966597 #> 6: Flusight-baseline       48       1  7.49960792 0.9659026096"},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_pmf_model_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform pmf model output into a forecast object — transform_pmf_model_out","title":"Transform pmf model output into a forecast object — transform_pmf_model_out","text":"Transform pmf model output forecast object","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_pmf_model_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform pmf model output into a forecast object — transform_pmf_model_out","text":"","code":"transform_pmf_model_out(   model_out_tbl,   oracle_output,   output_type_id_order = NULL )"},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_pmf_model_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform pmf model output into a forecast object — transform_pmf_model_out","text":"model_out_tbl Model output tibble predictions oracle_output Predictions generated oracle model knew observed target data values advance output_type_id_order ordinal variables pmf format, vector levels pmf forecasts, increasing order levels. order values output_type_id can found referencing hub's tasks.json configuration file. output types pmf, ignored.","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_pmf_model_out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform pmf model output into a forecast object — transform_pmf_model_out","text":"forecast_quantile","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_point_model_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform either mean or median model output into a point forecast object: — transform_point_model_out","title":"Transform either mean or median model output into a point forecast object: — transform_point_model_out","text":"Transform either mean median model output point forecast object:","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_point_model_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform either mean or median model output into a point forecast object: — transform_point_model_out","text":"","code":"transform_point_model_out(model_out_tbl, oracle_output, output_type)"},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_point_model_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform either mean or median model output into a point forecast object: — transform_point_model_out","text":"model_out_tbl Model output tibble predictions oracle_output Predictions generated oracle model knew observed target data values advance output_type Forecast output type: \"mean\" \"median\"","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_point_model_out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform either mean or median model output into a point forecast object: — transform_point_model_out","text":"forecast_point","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_point_model_out.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform either mean or median model output into a point forecast object: — transform_point_model_out","text":"function transforms model output tibble Hubverse format (either \"mean\" \"median\" output type) scoringutils \"point\" forecast object","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_quantile_model_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform quantile model output into a forecast object — transform_quantile_model_out","title":"Transform quantile model output into a forecast object — transform_quantile_model_out","text":"Transform quantile model output forecast object","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_quantile_model_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform quantile model output into a forecast object — transform_quantile_model_out","text":"","code":"transform_quantile_model_out(model_out_tbl, oracle_output)"},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_quantile_model_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform quantile model output into a forecast object — transform_quantile_model_out","text":"model_out_tbl Model output tibble predictions oracle_output Predictions generated oracle model knew observed target data values advance","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/reference/transform_quantile_model_out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform quantile model output into a forecast object — transform_quantile_model_out","text":"forecast_quantile","code":""},{"path":[]},{"path":"https://hubverse-org.github.io/hubEvals/dev/news/index.html","id":"hubevals-010","dir":"Changelog","previous_headings":"","what":"hubEvals 0.1.0","title":"hubEvals 0.1.0","text":"Add transform, transform_append, transform_label arguments score_model_out() computing scores transformed scales (e.g., log, sqrt). Supported quantile, mean, median output types (#48, #91).","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/news/index.html","id":"hubevals-001","dir":"Changelog","previous_headings":"","what":"hubEvals 0.0.1","title":"hubEvals 0.0.1","text":"Export functions transform_pmf_model_out(), transform_point_model_out(), transform_quantile_model_out() used transform hubverse model outputs scoringutils forecast object Update package dependencies use CRAN releases available Update README include simple examples package functions","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/news/index.html","id":"hubevals-0009001","dir":"Changelog","previous_headings":"","what":"hubEvals 0.0.0.9001","title":"hubEvals 0.0.0.9001","text":"Add score_model_out() function evaluating model outputs Add tests package Update organisation name hubverse-org","code":""},{"path":"https://hubverse-org.github.io/hubEvals/dev/news/index.html","id":"hubevals-0009000","dir":"Changelog","previous_headings":"","what":"hubEvals 0.0.0.9000","title":"hubEvals 0.0.0.9000","text":"Initial package dev setup.","code":""}]
